# Traditional ML Baselines for NLI

Traditional machine learning approaches using TF-IDF features for Natural Language Inference on ANLI R2 dataset.

---

## ğŸ“‹ Overview

This folder contains baseline experiments using classical ML algorithms before moving to deep learning approaches.

**Approach**: TF-IDF feature extraction + Traditional ML classifiers

---

## ğŸ“Š Results Summary

| Model | Test Accuracy | Test F1 (Macro) | Status |
|-------|--------------|-----------------|--------|
| **Logistic Regression** | **35.6%** | **0.339** | Beats Baseline âœ“ |
| **Random Forest** | 36.5% | 0.245 | Beats Baseline âœ“ |
| **XGBoost** | 38.7% | 0.329 | Beats Baseline âœ“ |
| *Baseline (DistilRoBERTa)* | *33.7%* | *0.242* | *Reference* |

**Best Traditional ML Model**: XGBoost with 38.7% accuracy

---

## ğŸ”§ Technical Details

### Feature Extraction
- **Method**: TF-IDF Vectorization
- **Max Features**: 15,000
- **N-gram Range**: (1, 2) - unigrams and bigrams
- **Text Preprocessing**: Lowercase, combined premise + hypothesis

### Models Trained
1. **Logistic Regression** - Linear classifier with L2 regularization
2. **Random Forest** - 100 trees, max depth 20
3. **XGBoost** - 100 estimators, max depth 6

---

## ğŸ“ Contents

```
BasicMLAlgos/
â”œâ”€â”€ train.ipynb          # Main training notebook
â””â”€â”€ README.md           # This file
```

---

## ğŸš€ Quick Start

```bash
# Install dependencies
pip install scikit-learn xgboost pandas numpy matplotlib seaborn datasets

# Run the notebook
jupyter notebook train.ipynb
```

The notebook will:
1. Load ANLI R2 dataset
2. Extract TF-IDF features
3. Train 3 ML models
4. Generate comparison plots and confusion matrices
5. Save results to `./artifacts/ml_baseline/results.json`

---

## ğŸ“ˆ Key Findings

âœ… **All models beat the baseline** (33.7%)  
âœ… **XGBoost performed best** among traditional ML (38.7%)  
âœ… **Logistic Regression had best F1** score (0.339)  
âš ï¸ **Significant overfitting observed** (72% train vs 36% test for LR)  
âš ï¸ **Deep learning outperforms** by 6-10% absolute (see main README)

---

## ğŸ“Š Artifacts Generated

After running the notebook, check `./artifacts/ml_baseline/`:
- `results.json` - Complete results and predictions
- `model_comparison.png` - Accuracy & F1 comparison plot
- `confusion_matrices.png` - Per-model confusion matrices
- `ml_baseline_log.txt` - Detailed training log
- `models/` - Saved model files (.pkl)

---

## ğŸ’¡ Why This Matters

These traditional ML baselines establish:
- **Lower bound performance**: What's achievable without deep learning
- **Feature engineering insights**: TF-IDF captures ~36% accuracy
- **Computational baseline**: <5 minutes training vs hours for BERT
- **Comparison reference**: Shows value of transformers (+6-12% improvement)

---

## ğŸ”— Next Steps

After reviewing these baselines:
1. See `../EDA/` for data analysis
2. Check `../Finetuning/Before/` for transformer baseline
3. Explore `../Finetuning/After/` for fine-tuned BERT models achieving 43-45% accuracy

---

**Note**: Traditional ML serves as an important baseline but is outperformed by fine-tuned transformers. However, these models are much faster to train and require no GPU!